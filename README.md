Repository contains jupyter notebooks for fine tune and inference `bert-base-multilingual-uncased` model. 

## Dataset
To tune the model was used dataset: [Link](https://www.kaggle.com/datasets/aybatov/toxic-russian-comments-from-pikabu-and-2ch)

## Model
The resulting model: [Link]()

## Metrics
|              | precision | recall | f1-score | support |
|-------------:|----------:|-------:|---------:|--------:|
|            0 |      0.93 |   0.94 |     0.94 |    1934 |
|            1 |      0.88 |   0.86 |     0.87 |     949 |
|     accuracy |           |        |     0.92 |    2883 |
|    macro avg |      0.91 |   0.90 |     0.90 |    2883 |
| weighted avg |      0.91 |   0.92 |     0.91 |    2883 |



